# AI Self-Discovery Evaluation Report

**Date:** 2025-11-30  
**Evaluator:** Claude (AI Agent via ECA)  
**Test Host:** elvira (Rocky Linux 9.6)

## Executive Summary

**Rating: ⭐⭐⭐⭐⭐ Excellent**

The Bashible project successfully guides an AI agent to self-discover and use Ansible within approximately 2 minutes. The AGENTS.md documentation is exceptionally well-designed for AI consumption—it's action-oriented, shell-first, and provides exactly the right patterns for incremental exploration.

---

## What Worked Exceptionally Well

### 1. Shell-First Philosophy
The emphasis on "ask the shell, not the docs" is perfect for AI agents. I was able to immediately:
```bash
ansible-inventory --graph          # See infrastructure structure
ansible elvira -m ping             # Verify connectivity
ansible elvira -m setup            # Gather facts
```

### 2. Discovery Command Tables
The tables mapping questions to commands are gold:
| Question | Command |
|----------|---------|
| What hosts exist? | `ansible-inventory --list \| jq 'keys'` |
| Host variables? | `ansible-inventory --host <hostname>` |

These allowed instant autonomous exploration without needing to ask the user.

### 3. Graduated Execution Pattern
The exploration pattern (ping → facts → ad-hoc → dry-run → apply) is exactly right:
```bash
ansible elvira -m ping                    # ✓ Worked
ansible elvira -m setup -a 'filter=...'   # ✓ Worked  
ansible elvira -m shell -a 'uptime'       # ✓ Worked
ansible-playbook site.yml --check --diff  # ✓ Worked
```

### 4. Verify After Action
The ad-hoc → playbook → ad-hoc verify workflow with the verification table is extremely practical:
```bash
# After Install package → verify with:
ansible elvira -m shell -a "which nginx"  # nginx exists ✓
ansible elvira -m stat -a "path=/etc/nginx/nginx.conf"  # config exists ✓
```

### 5. Clear Project Structure
The directory layout is immediately comprehensible:
```
inventory/hosts.yml     → Where hosts live
playbooks/site.yml      → Entry point
roles/common/           → Reusable automation
ansible.cfg             → Configuration
```

---

## Test Host Discovery (elvira)

Successfully discovered:
- **OS:** Rocky Linux 9.6 "Blue Onyx" (RHEL family)
- **Uptime:** 12 days, 18 hours
- **Memory:** 3.6GB total, 2.7GB available
- **Disk:** 64GB root, 12% used
- **Running Services:** nginx, sshd, chronyd, firewalld, gollum (container)
- **Open Ports:** 22 (SSH), 80 (nginx), 4567 (gollum)
- **Python:** 3.11 (auto-discovered by Ansible)

All this discovered through shell commands as documented in AGENTS.md.

---

## Minor Observations

### 1. ~~Elvira Host Missing Variables~~ ✅ Fixed
The `elvira` host now has explicit `ansible_host: 10.10.100.2` configured.

### 2. Nginx Returns 403
```bash
ansible elvira -m uri -a "url=http://localhost status_code=200"  # Failed
```
Localhost returns 403 (Forbidden) - not a project issue, just noted for awareness.

### 3. `.venv` Already Existed
The `./install_ansible` script correctly detected existing venv and skipped recreation. The "If already set up, just activate" guidance worked.

---

## What the AI Agent Did Autonomously

1. **Read AGENTS.md** - Understood the shell-driven philosophy
2. **Activated venv** - `source .venv/bin/activate`
3. **Discovered inventory** - `ansible-inventory --graph`
4. **Tested connectivity** - `ansible elvira -m ping`
5. **Gathered facts** - `ansible elvira -m setup` with filters
6. **Ran ad-hoc commands** - shell, stat, service_facts, package_facts, getent
7. **Inspected playbook** - `ansible-playbook site.yml --list-tasks`
8. **Dry-ran playbook** - `ansible-playbook site.yml --check --diff`
9. **Ran playbook** - `ansible-playbook site.yml --limit elvira -v`

All of this without asking the user any questions. The documentation was sufficient.

---

## Recommendations for Improvement

1. ~~**Add explicit host vars for elvira**~~ ✅ Done

2. ~~**Add a "First Time? Start Here" section**~~ ✅ Added as `## TL;DR` at top of AGENTS.md

3. ~~**Consider adding example tasks**~~ ✅ Added system summary task (read-only, demonstrates Jinja templating)

---

## Conclusion

This project demonstrates excellent AI-agent ergonomics. The key success factors:

- **Action over explanation** - Commands to run, not prose to read
- **Incremental discovery** - Build understanding step by step
- **Verification patterns** - Check state before and after
- **Working test infrastructure** - A real host (elvira) to experiment with

An AI agent with shell access can become productive with Ansible in this repo within minutes. This is a model for how infrastructure projects should be documented for AI collaboration.

---

*Report generated by Claude via ECA (Editor Code Assistant)*
